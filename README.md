# Fashion Store Chatbot

Chatbot customer support untuk platform toko online fashion menggunakan LLM lokal dengan Ollama dan Llama3.2:3b.

## ğŸš€ Cara Instalasi & Requirements

### Prerequisites
- Python 3.11+
- Docker & Docker Compose
- Git

### Option 1: Docker Setup (Recommended)

```bash
# Clone repository
git clone <repository-url>
cd chatbot-challenge

# Start services
docker-compose up --build -d

# Download model (first time only)
docker exec ollama-server ollama pull llama3.2:3b

# Test API
curl http://localhost:8000/
```

### Option 2: Local Development Setup

```bash
# Clone repository
git clone <repository-url>
cd chatbot-challenge

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Linux/Mac:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install & start Ollama
curl -fsSL https://ollama.com/install.sh | sh
ollama serve &
ollama pull llama3.2:3b

# Initialize database
python init_db.py

# Start FastAPI server
uvicorn main:app --reload --port 8000
```

## ğŸ—„ï¸ Desain Database

### ERD Overview
```
conversation_history          products                orders
â”œâ”€â”€ id (PK)                  â”œâ”€â”€ id (PK)            â”œâ”€â”€ id (PK)
â”œâ”€â”€ session_id               â”œâ”€â”€ name               â”œâ”€â”€ customer_name
â”œâ”€â”€ role                     â”œâ”€â”€ description        â”œâ”€â”€ status
â”œâ”€â”€ message                  â”œâ”€â”€ price              â”œâ”€â”€ shipping_provider
â””â”€â”€ timestamp                â”œâ”€â”€ category           â”œâ”€â”€ eta
                             â””â”€â”€ stock              â””â”€â”€ total_amount
```

### Tabel `conversation_history`
Menyimpan history percakapan untuk memory system
- `session_id`: Identifier unik per user session
- `role`: 'user' atau 'assistant'
- `message`: Isi pesan
- `timestamp`: Waktu pesan (auto-generated)

### Tabel `products`
Katalog produk fashion
- `name`: Nama produk (Dress Summer, Jaket Denim, dll)
- `description`: Deskripsi detail produk
- `price`: Harga dalam Rupiah
- `category`: Kategori produk
- `stock`: Jumlah stok tersedia

### Tabel `orders`
Data pesanan customer
- `id`: Nomor pesanan (2001, 2002, 2003)
- `status`: Status pesanan (Dikirim, Dikemas, Menunggu Pembayaran)
- `shipping_provider`: Provider pengiriman (JNE, SiCepat)
- `eta`: Estimasi waktu tiba

## ğŸ“š Library & Framework

### Core Dependencies
- **FastAPI**: Modern web framework untuk API
- **Uvicorn**: ASGI server untuk FastAPI
- **Langchain**: Framework untuk aplikasi LLM
- **Langchain-Ollama**: Ollama integration untuk Langchain
- **Pydantic**: Data validation dan serialization

### Infrastructure
- **SQLite**: Database ringan untuk development
- **Docker**: Containerization untuk deployment
- **Ollama**: Runtime untuk LLM lokal

## ğŸ¤– Model LLM

**Model**: `llama3.2:3b`
- **Size**: ~2GB
- **Provider**: Ollama (local deployment)
- **Temperature**: 0.1 (konsisten responses)
- **Context**: Support conversation memory
- **Language**: Dioptimasi untuk Bahasa Indonesia

## ğŸ’¬ Daftar Pertanyaan yang Dapat Dijawab

### 1. Status Pesanan
```
âœ… "Status pesanan 2001 gimana?"
âœ… "Dimana pesanan saya 2002?"
âœ… "Pesanan 2003 udah sampai belum?"
âŒ "Pesanan 9999" â†’ Tidak ditemukan
```

### 2. Informasi Produk
```
âœ… "Info tentang Dress Summer"
âœ… "Jaket Denim bagaimana?"
âœ… "Produk apa saja yang tersedia?"
âœ… "Harga Kemeja Formal berapa?"
```

### 3. Kebijakan Garansi
```
âœ… "Bagaimana cara claim garansi?"
âœ… "Garansi berlaku berapa lama?"
âœ… "Bisa retur tidak?"
âœ… "Syarat tukar ukuran gimana?"
```

### 4. Conversation Memory
```
âœ… "Nama saya Malinda" â†’ Disimpan untuk recall
âœ… "Siapa nama saya?" â†’ "Nama Anda adalah Malinda"
âœ… "Apa pertanyaan sebelumnya?" â†’ Recall 3 interaksi terakhir
```

### 5. General Conversation
```
âœ… "Halo" â†’ Greeting response
âœ… "Terima kasih" â†’ Polite response
âœ… "Selamat pagi" â†’ Natural conversation
```

## ğŸ› ï¸ Daftar Tool Calls

### `get_order_status(order_id)`
**Fungsi**: Mengecek status pesanan berdasarkan ID
**Input**: Nomor pesanan (2001, 2002, 2003)
**Output**: Status, provider pengiriman, dan ETA
```python
# Contoh usage
get_order_status("2001")
# Return: "Pesanan #2001 Dikirim via JNE, estimasi tiba 2025-09-25."
```

### `get_product_info(product_name)`
**Fungsi**: Mendapatkan informasi detail produk
**Input**: Nama produk (partial matching)
**Output**: Nama, deskripsi, harga, dan stok
```python
# Contoh usage
get_product_info("Dress Summer")
# Return: Detail lengkap dengan harga Rp 299.000
```

### `get_warranty_policy(question)`
**Fungsi**: Menampilkan kebijakan garansi dan retur
**Input**: Pertanyaan terkait garansi (optional)
**Output**: Policy lengkap 30 hari garansi
```python
# Contoh usage
get_warranty_policy("")
# Return: Kebijakan lengkap garansi & retur
```

## ğŸ—ï¸ Architecture & Flow

### Request Flow
```
User Input â†’ Intent Classification â†’ Tool Selection â†’ LLM Processing â†’ Response
     â†“
Database â† Memory Loading â† Session Management â† Response Cleanup
```

### Intent Classification
- **Rule-based detection** untuk queries umum (greeting, introduction)
- **Keyword matching** untuk tool selection (pesanan, produk, garansi)
- **Agent processing** untuk complex queries
- **Memory queries** untuk conversation recall

### Memory System
- **3 interaksi terakhir** per session tersimpan
- **Automatic loading** dari database setiap request
- **Session isolation** antar user
- **Name extraction & recall** untuk personalisasi

## ğŸ§ª Testing

### API Testing
```bash
# Health check
curl http://localhost:8000/

# Chat endpoint
curl -X POST "http://localhost:8000/chat" \
     -H "Content-Type: application/json" \
     -d '{"session_id": "test", "message": "Halo!"}'
```

### Automated Testing
```bash
# Run test scenarios
python test/test_scenarios.py
```

### Test Coverage
- âœ… All 3 core requirements (pesanan, produk, garansi)
- âœ… Memory functionality (3 interaksi)
- âœ… Error handling (invalid inputs)
- âœ… Session isolation
- âœ… Tool integration

## ğŸ³ Docker Deployment

### Services Architecture
```yaml
ollama:          # Official Ollama image
  - Port: 11434
  - Model: llama3.2:3b
  
chatbot:         # Custom Python application
  - Port: 8000
  - FastAPI + Langchain
  - Database: SQLite volume
```

### Commands
```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down

# Rebuild after changes
docker-compose up --build
```

## ğŸ”§ Development

### Local Development
```bash
# Start only Ollama in Docker
docker-compose up ollama -d

# Run chatbot locally with hot reload
uvicorn main:app --reload --port 8000
```

### Code Structure
```
chatbot-challenge/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ chatbot.py      # Main chat logic
â”‚   â”œâ”€â”€ db.py           # Database operations
â”‚   â””â”€â”€ tools.py        # LLM tools
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ schema.sql      # Database schema
â”‚   â””â”€â”€ *.db           # SQLite files
â”œâ”€â”€ test/
â”‚   â””â”€â”€ test_scenarios.py
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ main.py            # FastAPI app
â””â”€â”€ requirements.txt
```
---

**Developed for Synapsis Jr. AI Engineer Challenge**